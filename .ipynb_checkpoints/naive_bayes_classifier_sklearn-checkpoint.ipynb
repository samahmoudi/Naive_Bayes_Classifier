{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0496b720-5c9f-416a-9284-5f57e956d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           int64\n",
      "diagnosis                   object\n",
      "radius_mean                float64\n",
      "texture_mean               float64\n",
      "perimeter_mean             float64\n",
      "area_mean                  float64\n",
      "smoothness_mean            float64\n",
      "compactness_mean           float64\n",
      "concavity_mean             float64\n",
      "concave points_mean        float64\n",
      "symmetry_mean              float64\n",
      "fractal_dimension_mean     float64\n",
      "radius_se                  float64\n",
      "texture_se                 float64\n",
      "perimeter_se               float64\n",
      "area_se                    float64\n",
      "smoothness_se              float64\n",
      "compactness_se             float64\n",
      "concavity_se               float64\n",
      "concave points_se          float64\n",
      "symmetry_se                float64\n",
      "fractal_dimension_se       float64\n",
      "radius_worst               float64\n",
      "texture_worst              float64\n",
      "perimeter_worst            float64\n",
      "area_worst                 float64\n",
      "smoothness_worst           float64\n",
      "compactness_worst          float64\n",
      "concavity_worst            float64\n",
      "concave points_worst       float64\n",
      "symmetry_worst             float64\n",
      "fractal_dimension_worst    float64\n",
      "Unnamed: 32                float64\n",
      "dtype: object\n",
      "id                           0\n",
      "diagnosis                    0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "dtype: int64\n",
      "Label Mapping: {'M': 0, 'B': 1}\n",
      "Accuracy: 0.9736842105263158 \n",
      "\n",
      "\n",
      "Category M\n",
      "                     Actual Positive  Actual Negative\n",
      "Predicted Positive               40                3\n",
      "Predicted Negative                0               71 \n",
      "\n",
      " Category B\n",
      "                     Actual Positive  Actual Negative\n",
      "Predicted Positive               71                3\n",
      "Predicted Negative                0               40 \n",
      "\n",
      "\n",
      "Category M Precision = 1.0 Recall = 0.9302325581395349\n",
      "Category B Precision = 0.9594594594594594 Recall = 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection as sms\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ================================\n",
    "# Naive Bayes Classifier using Scikit-Learn\n",
    "# This script implements a Naive Bayes Classifier using Scikit-Learn's GaussianNB\n",
    "# for the Breast Cancer Wisconsin dataset.\n",
    "# ================================\n",
    "\n",
    "# Load and preprocess dataset\n",
    "# ================================\n",
    "file_path = r'data.csv'  # Path to the dataset file\n",
    "\n",
    "# Load the dataset\n",
    "raw_dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Print the data types of each column to verify correctness\n",
    "print(raw_dataset.dtypes)\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(raw_dataset.isnull().sum())\n",
    "\n",
    "# Drop non-informative columns (e.g., 'Unnamed: 32' and 'id')\n",
    "raw_dataset = raw_dataset.drop(['Unnamed: 32', 'id'], axis=1)  # Drop unnecessary columns\n",
    "\n",
    "# Convert qualitative labels to numerical ones\n",
    "def label_to_numeric(column):\n",
    "    if column.dtype == 'object':\n",
    "        unique_labels, _ = pd.factorize(column)\n",
    "        return pd.Series(unique_labels, index=column.index)\n",
    "    return column\n",
    "\n",
    "dataset = raw_dataset.apply(label_to_numeric)\n",
    "\n",
    "# Create a mapping from original labels to numeric ones\n",
    "label_map = dict(zip(raw_dataset['diagnosis'], dataset['diagnosis']))\n",
    "print(\"Label Mapping:\", label_map)\n",
    "\n",
    "# Feature extraction and train-test split\n",
    "# ================================\n",
    "features = list(set(dataset.columns) - {'diagnosis'})  # Extract feature labels\n",
    "label = dataset['diagnosis']\n",
    "data = dataset[features]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "data_trainset, data_testset, label_trainset, label_testset = sms.train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "# ================================\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(data_trainset, label_trainset)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "prediction = naive_bayes_model.predict(data_testset)\n",
    "\n",
    "# Evaluate the model\n",
    "# ================================\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(label_testset, prediction)\n",
    "print(\"Accuracy:\", accuracy, '\\n\\n')\n",
    "\n",
    "# Create a DataFrame for comparison\n",
    "Comparison = pd.concat([label_testset.reset_index(drop=True), pd.Series(prediction)], axis=1)\n",
    "Comparison.rename(columns={0: 'classifier'}, inplace=True)\n",
    "\n",
    "# Calculate confusion matrices\n",
    "# ================================\n",
    "# Confusion matrix for category M (Malignant)\n",
    "M_TP = ((Comparison['diagnosis'] == 0) & (Comparison['classifier'] == 0)).sum()\n",
    "M_FN = ((Comparison['diagnosis'] == 0) & (Comparison['classifier'] == 1)).sum()\n",
    "M_TN = ((Comparison['diagnosis'] == 1) & (Comparison['classifier'] == 1)).sum()\n",
    "M_FP = ((Comparison['diagnosis'] == 1) & (Comparison['classifier'] == 0)).sum()\n",
    "\n",
    "M_confusion_matrix = confusion_matrix(label_testset, prediction)\n",
    "M_confusion_matrix = pd.DataFrame(M_confusion_matrix, columns=['Actual Positive', 'Actual Negative'], index=['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "# Confusion matrix for category B (Benign)\n",
    "B_TP = ((Comparison['diagnosis'] == 1) & (Comparison['classifier'] == 1)).sum()\n",
    "B_FN = ((Comparison['diagnosis'] == 1) & (Comparison['classifier'] == 0)).sum()\n",
    "B_TN = ((Comparison['diagnosis'] == 0) & (Comparison['classifier'] == 0)).sum()\n",
    "B_FP = ((Comparison['diagnosis'] == 0) & (Comparison['classifier'] == 1)).sum()\n",
    "\n",
    "B_confusion_matrix = {\n",
    "    'Actual Positive': [B_TP, B_FN],\n",
    "    'Actual Negative': [B_FP, B_TN],\n",
    "}\n",
    "B_confusion_matrix = pd.DataFrame(B_confusion_matrix, columns=['Actual Positive', 'Actual Negative'], index=['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "# Print confusion matrices\n",
    "print('Category M\\n', M_confusion_matrix, '\\n\\n', 'Category B\\n', B_confusion_matrix, '\\n\\n')\n",
    "\n",
    "# Calculate precision and recall for both categories\n",
    "M_Precision = M_TP / (M_TP + M_FP)\n",
    "M_Recall = M_TP / (M_TP + M_FN)\n",
    "print('Category M', 'Precision =', M_Precision, 'Recall =', M_Recall)\n",
    "\n",
    "B_Precision = B_TP / (B_TP + B_FP)\n",
    "B_Recall = B_TP / (B_TP + B_FN)\n",
    "print('Category B', 'Precision =', B_Precision, 'Recall =', B_Recall)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
